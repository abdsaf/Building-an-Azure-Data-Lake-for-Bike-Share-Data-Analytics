{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6da506ea-590e-41f6-aee0-d41f941ca53f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "riderSchema = StructType([\n",
    "    StructField(\"rider_id\", IntegerType()),\n",
    "    StructField(\"first\", StringType()),\n",
    "    StructField(\"last\", StringType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"birthday\", DateType()),\n",
    "    StructField(\"account_start_date\", DateType()),\n",
    "    StructField(\"account_end_date\", DateType()),\n",
    "    StructField(\"is_member\", BooleanType())\n",
    "    ])\n",
    "\n",
    "paymentSchema = StructType([\n",
    "    StructField(\"payment_id\", IntegerType()),\n",
    "    StructField(\"date\", DateType()),\n",
    "    StructField(\"amount\", FloatType()),\n",
    "    StructField(\"rider_id\", IntegerType())\n",
    "    \n",
    "    ])\n",
    "\n",
    "stationSchema = StructType([\n",
    "    StructField(\"station_id\", StringType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"latitude\", FloatType()),\n",
    "    StructField(\"longitude\", FloatType())\n",
    "    \n",
    "    ])\n",
    "\n",
    "tripSchema = StructType([\n",
    "    StructField(\"trip_id\", StringType()),\n",
    "    StructField(\"rideable_type\", StringType()),\n",
    "    StructField(\"start_at\", TimestampType()),\n",
    "    StructField(\"ended_at\", TimestampType()),\n",
    "    StructField(\"start_station_id\", StringType()),\n",
    "    StructField(\"end_station_id\", StringType()),\n",
    "    StructField(\"rider_id\", IntegerType())\n",
    "    \n",
    "    ])\n",
    "df = spark.read.load('/FileStore/bikeshare_source/riders.csv',\n",
    "    format='csv',\n",
    "    schema=riderSchema,\n",
    "    header=False)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/riders\")\n",
    "\n",
    "df = spark.read.load('/FileStore/bikeshare_source/payments.csv',\n",
    "    format='csv',\n",
    "    schema=paymentSchema,\n",
    "    header=False)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/payments\")\n",
    "\n",
    "df = spark.read.load('/FileStore/bikeshare_source/stations.csv',\n",
    "    format='csv',\n",
    "    schema=stationSchema,\n",
    "    header=False)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/stations\")\n",
    "\n",
    "df = spark.read.load('/FileStore/bikeshare_source/trips.csv',\n",
    "    format='csv',\n",
    "    schema=tripSchema,\n",
    "    header=False)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/trips\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e077025-5bbc-4d25-ac58-af878ca18376",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "DROP TABLE IF EXISTS riders;\n",
    "CREATE TABLE riders \n",
    "(rider_id INTEGER , \n",
    "first VARCHAR(50), \n",
    "last VARCHAR(50), \n",
    "address VARCHAR(100), \n",
    "birthday DATE, \n",
    "account_start_date DATE, \n",
    "account_end_date DATE, \n",
    "is_member BOOLEAN)\n",
    "USING DELTA;\n",
    "\n",
    "DROP TABLE IF EXISTS payments;\n",
    "CREATE TABLE payments (payment_id INTEGER , date DATE, amount FLOAT, rider_id INTEGER)\n",
    "USING DELTA;\n",
    "\n",
    "DROP TABLE IF EXISTS stations;\n",
    "CREATE TABLE stations (station_id VARCHAR(50) , name VARCHAR(75), latitude FLOAT, longitude FLOAT)\n",
    "USING DELTA;\n",
    "\n",
    "DROP TABLE IF EXISTS trips;\n",
    "CREATE TABLE trips (trip_id VARCHAR(50) , rideable_type VARCHAR(75), start_at TIMESTAMP, ended_at TIMESTAMP, start_station_id VARCHAR(50), end_station_id VARCHAR(50), rider_id INTEGER)\n",
    "USING DELTA;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe7b456a-fe96-4c20-911b-3bc46d57638f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.format(\"delta\").load(\"/delta/riders\")\n",
    "df.write.format(\"delta\").mode(\"append\").saveAsTable(\"riders123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2135357-7ac5-4a56-aab9-0beda00e03b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4261167381502954,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Building an Azure Data Lake for Bike Share Data Analytics",
   "notebookOrigID": 4261167381502952,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
